import formidable from 'formidable'
import fs from 'fs/promises'
import * as tf from '@tensorflow/tfjs-node'
import * as cocoSsd from '@tensorflow-models/coco-ssd'
import sharp from 'sharp'
import { v4 as uuidv4 } from 'uuid'
import path from 'path'
import { createProcessingLogger, PROCESSING_STEPS } from '../utils/processing-logger.js'

let carDetectionModel = null

// Nuevos pasos espec√≠ficos para la pipeline simplificada
const PLATE_PROCESSING_STEPS = {
  ORIGINAL: 'original',
  VEHICLE_DETECTED: 'vehicle_detected',
  GRAYSCALE: 'grayscale', 
  EDGE_DETECTION: 'edge_detection',
  CONTOURS_FOUND: 'contours_found',
  PLATE_CANDIDATES: 'plate_candidates',
  PLATE_EXTRACTED: 'plate_extracted',
  PERSPECTIVE_CORRECTED: 'perspective_corrected',
  FINAL_NORMALIZED: 'final_normalized'
}

async function loadCarDetectionModel(logger) {
  if (!carDetectionModel) {
    try {
      logger.info('üîß Cargando modelo de detecci√≥n de veh√≠culos...')
      await tf.ready()
      carDetectionModel = await cocoSsd.load({
        base: 'mobilenet_v2'
      })
      logger.success('‚úÖ Modelo de detecci√≥n listo para usar')
    } catch (error) {
      logger.warning(`‚ö†Ô∏è Usando modelo fallback: ${error.message}`)
      carDetectionModel = await cocoSsd.load()
      logger.info('‚úÖ Modelo b√°sico cargado')
    }
  }
  return carDetectionModel
}

async function detectVehicle(imagePath, logger) {
  try {
    logger.info('üöó Paso 1: Buscando veh√≠culos en la imagen...')
    const model = await loadCarDetectionModel(logger)
    const imageBuffer = await fs.readFile(imagePath)
    const imageTensor = tf.node.decodeImage(imageBuffer)
    
    logger.info('üîç Analizando con IA para encontrar veh√≠culos...')
    const predictions = await model.detect(imageTensor)
    imageTensor.dispose()
    
    const vehicleClasses = ['car', 'truck', 'bus', 'motorcycle', 'bicycle']
    const vehicleDetections = predictions.filter(pred => 
      vehicleClasses.includes(pred.class) && pred.score > 0.15
    )
    
    if (vehicleDetections.length === 0) {
      logger.warning('‚ö†Ô∏è No se detectaron veh√≠culos, procesaremos toda la imagen')
      return {
        hasVehicle: false,
        bbox: null,
        confidence: 0,
        vehicleType: null
      }
    }
    
    // Tomar el veh√≠culo con mayor confianza
    vehicleDetections.sort((a, b) => b.score - a.score)
    const bestVehicle = vehicleDetections[0]
    
    logger.success(`‚úÖ Veh√≠culo encontrado: ${bestVehicle.class}`)
    logger.info(`üìä Confianza: ${(bestVehicle.score * 100).toFixed(1)}%`)
    logger.info(`üìç Posici√≥n: [${bestVehicle.bbox.map(n => Math.round(n)).join(', ')}]`)
    
    // Crear imagen con veh√≠culo marcado
    const markedBuffer = await createVehicleMarkedImage(imageBuffer, bestVehicle.bbox, logger)
    await logger.saveProcessedImage(markedBuffer, PLATE_PROCESSING_STEPS.VEHICLE_DETECTED, 
      `Veh√≠culo detectado: ${bestVehicle.class} (${(bestVehicle.score * 100).toFixed(1)}%)`)
    
    return {
      hasVehicle: true,
      bbox: bestVehicle.bbox,
      confidence: bestVehicle.score,
      vehicleType: bestVehicle.class
    }
  } catch (error) {
    logger.error(`‚ùå Error detectando veh√≠culo: ${error.message}`)
    return { hasVehicle: false, bbox: null, confidence: 0, vehicleType: null }
  }
}

async function createVehicleMarkedImage(imageBuffer, bbox, logger) {
  try {
    const [x, y, width, height] = bbox
    
    // Crear overlay con el rect√°ngulo del veh√≠culo
    const image = sharp(imageBuffer)
    const { width: imgWidth, height: imgHeight } = await image.metadata()
    
    // Crear SVG overlay
    const svgOverlay = `
      <svg width="${imgWidth}" height="${imgHeight}">
        <rect x="${x}" y="${y}" width="${width}" height="${height}" 
              fill="none" stroke="lime" stroke-width="3" opacity="0.8"/>
        <text x="${x}" y="${y - 10}" fill="lime" font-size="20" font-weight="bold">Veh√≠culo</text>
      </svg>
    `
    
    return await image
      .composite([{ input: Buffer.from(svgOverlay), top: 0, left: 0 }])
      .jpeg()
      .toBuffer()
  } catch (error) {
    logger.warning('‚ö†Ô∏è No se pudo crear imagen marcada, usando original')
    return imageBuffer
  }
}

async function findPlateContours(imagePath, vehicleBbox, logger) {
  try {
    logger.info('üîç Paso 2: Buscando contornos de placas...')
    
    // Determinar √°rea de b√∫squeda
    let searchArea = null
    if (vehicleBbox) {
      // Enfocar en la parte inferior del veh√≠culo donde est√°n las placas
      const [x, y, width, height] = vehicleBbox
      searchArea = {
        left: Math.max(0, Math.round(x)),
        top: Math.max(0, Math.round(y + height * 0.6)), // 60% hacia abajo
        width: Math.round(width),
        height: Math.round(height * 0.4) // 40% inferior del veh√≠culo
      }
      logger.info(`üìç Enfocando b√∫squeda en √°rea del veh√≠culo: ${searchArea.width}x${searchArea.height}`)
    } else {
      logger.info('üîç Buscando en toda la imagen')
    }
    
    // Paso 1: Convertir a escala de grises
    logger.info('üé® Convirtiendo a escala de grises...')
    const baseImage = sharp(imagePath)
    const metadata = await baseImage.metadata()
    
    let workingImage = baseImage
    if (searchArea) {
      // Recortar √°rea de b√∫squeda
      workingImage = baseImage.extract(searchArea)
    }
    
    const grayscaleBuffer = await workingImage
      .greyscale()
      .jpeg()
      .toBuffer()
    
    await logger.saveProcessedImage(grayscaleBuffer, PLATE_PROCESSING_STEPS.GRAYSCALE, 
      'Imagen convertida a escala de grises')
    
    // Paso 2: Detecci√≥n de bordes
    logger.info('üñºÔ∏è Aplicando detecci√≥n de bordes...')
    const edgeBuffer = await sharp(grayscaleBuffer)
      .convolve({
        width: 3,
        height: 3,
        kernel: [-1, -1, -1, -1, 8, -1, -1, -1, -1] // Kernel de detecci√≥n de bordes
      })
      .normalize()
      .jpeg()
      .toBuffer()
    
    await logger.saveProcessedImage(edgeBuffer, PLATE_PROCESSING_STEPS.EDGE_DETECTION, 
      'Bordes detectados usando convoluci√≥n')
    
    // Paso 3: Encontrar contornos rectangulares (simulaci√≥n)
    logger.info('üìê Analizando contornos rectangulares...')
    const contourCandidates = await findRectangularContours(edgeBuffer, logger)
    
    if (contourCandidates.length === 0) {
      logger.warning('‚ö†Ô∏è No se encontraron contornos rectangulares v√°lidos')
      return { success: false, plateRegions: [] }
    }
    
    logger.success(`‚úÖ Encontrados ${contourCandidates.length} candidatos de placa`)
    
    // Crear imagen con contornos marcados
    const contoursBuffer = await createContoursImage(grayscaleBuffer, contourCandidates, logger)
    await logger.saveProcessedImage(contoursBuffer, PLATE_PROCESSING_STEPS.CONTOURS_FOUND, 
      `${contourCandidates.length} contornos rectangulares encontrados`)
    
    return {
      success: true,
      plateRegions: contourCandidates,
      searchArea
    }
    
  } catch (error) {
    logger.error(`‚ùå Error buscando contornos: ${error.message}`)
    return { success: false, plateRegions: [] }
  }
}

async function findRectangularContours(imageBuffer, logger) {
  // Simulaci√≥n de detecci√≥n de contornos rectangulares
  // En una implementaci√≥n real, usar√≠as OpenCV o una librer√≠a similar
  
  logger.info('üîç Simulando detecci√≥n de contornos...')
  
  const image = sharp(imageBuffer)
  const { width, height } = await image.metadata()
  
  // Simular varios candidatos de placa con diferentes tama√±os y posiciones
  const candidates = [
    {
      id: 1,
      corners: [
        [width * 0.2, height * 0.4],  // Top-left
        [width * 0.8, height * 0.35], // Top-right (ligeramente inclinado)
        [width * 0.82, height * 0.65], // Bottom-right
        [width * 0.18, height * 0.7]   // Bottom-left (trapecio)
      ],
      confidence: 0.89,
      aspectRatio: 4.5, // Ratio t√≠pico de placa mexicana
      area: (width * 0.6) * (height * 0.25)
    },
    {
      id: 2,
      corners: [
        [width * 0.1, height * 0.6],
        [width * 0.5, height * 0.58],
        [width * 0.52, height * 0.8],
        [width * 0.08, height * 0.82]
      ],
      confidence: 0.65,
      aspectRatio: 3.8,
      area: (width * 0.4) * (height * 0.2)
    }
  ]
  
  // Filtrar candidatos por aspectRatio t√≠pico de placas (entre 3:1 y 5:1)
  const validCandidates = candidates.filter(candidate => 
    candidate.aspectRatio >= 3.0 && candidate.aspectRatio <= 5.5 && candidate.confidence > 0.6
  )
  
  logger.info(`üéØ ${validCandidates.length} candidatos v√°lidos por aspect ratio`)
  
  return validCandidates
}

async function createContoursImage(baseBuffer, contours, logger) {
  try {
    const image = sharp(baseBuffer)
    const { width, height } = await image.metadata()
    
    // Crear SVG con los contornos
    let svgElements = ''
    contours.forEach((contour, index) => {
      const points = contour.corners.map(([x, y]) => `${x},${y}`).join(' ')
      const color = index === 0 ? 'lime' : 'yellow' // Mejor candidato en verde
      
      svgElements += `
        <polygon points="${points}" fill="none" stroke="${color}" stroke-width="2" opacity="0.8"/>
        <text x="${contour.corners[0][0]}" y="${contour.corners[0][1] - 5}" 
              fill="${color}" font-size="12" font-weight="bold">
          Placa ${index + 1} (${(contour.confidence * 100).toFixed(0)}%)
        </text>
      `
    })
    
    const svgOverlay = `
      <svg width="${width}" height="${height}">
        ${svgElements}
      </svg>
    `
    
    return await image
      .composite([{ input: Buffer.from(svgOverlay), top: 0, left: 0 }])
      .jpeg()
      .toBuffer()
  } catch (error) {
    logger.warning('‚ö†Ô∏è Error creando imagen de contornos, usando base')
    return baseBuffer
  }
}

async function extractAndCorrectPlate(imagePath, plateRegion, searchArea, logger) {
  try {
    const bestPlate = plateRegion.plateRegions[0] // Tomar el mejor candidato
    
    logger.info('‚úÇÔ∏è Paso 3: Extrayendo regi√≥n de la placa...')
    logger.info(`üéØ Procesando candidato con confianza ${(bestPlate.confidence * 100).toFixed(1)}%`)
    
    // Ajustar coordenadas si hay √°rea de b√∫squeda
    let adjustedCorners = bestPlate.corners
    if (searchArea) {
      adjustedCorners = bestPlate.corners.map(([x, y]) => [
        x + searchArea.left,
        y + searchArea.top
      ])
    }
    
    // Paso 1: Extraer regi√≥n rectangular que contenga la placa
    const boundingRect = calculateBoundingRect(adjustedCorners)
    logger.info(`üìè Regi√≥n detectada: ${boundingRect.width}x${boundingRect.height} p√≠xeles`)
    
    const extractedBuffer = await sharp(imagePath)
      .extract({
        left: Math.max(0, boundingRect.x),
        top: Math.max(0, boundingRect.y),
        width: boundingRect.width,
        height: boundingRect.height
      })
      .jpeg()
      .toBuffer()
    
    await logger.saveProcessedImage(extractedBuffer, PLATE_PROCESSING_STEPS.PLATE_EXTRACTED, 
      `Regi√≥n de placa extra√≠da: ${boundingRect.width}x${boundingRect.height}`)
    
    // Paso 2: Correcci√≥n de perspectiva (trapecio ‚Üí rect√°ngulo)
    logger.info('üìê Paso 4: Corrigiendo perspectiva de trapecio a rect√°ngulo...')
    
    const correctedBuffer = await correctPerspective(extractedBuffer, adjustedCorners, boundingRect, logger)
    await logger.saveProcessedImage(correctedBuffer, PLATE_PROCESSING_STEPS.PERSPECTIVE_CORRECTED, 
      'Perspectiva corregida: trapecio transformado a rect√°ngulo')
    
    // Paso 3: Normalizaci√≥n final
    logger.info('‚ú® Paso 5: Aplicando normalizaci√≥n final...')
    
    const finalBuffer = await normalizePlateImage(correctedBuffer, logger)
    await logger.saveProcessedImage(finalBuffer, PLATE_PROCESSING_STEPS.FINAL_NORMALIZED, 
      'Imagen final normalizada y optimizada para an√°lisis')
    
    logger.success('üéâ ¬°Placa extra√≠da y normalizada exitosamente!')
    
    return {
      success: true,
      plateImage: finalBuffer,
      plateRegion: bestPlate,
      dimensions: boundingRect
    }
    
  } catch (error) {
    logger.error(`‚ùå Error extrayendo placa: ${error.message}`)
    return { success: false }
  }
}

function calculateBoundingRect(corners) {
  const xs = corners.map(([x, y]) => x)
  const ys = corners.map(([x, y]) => y)
  
  const minX = Math.min(...xs)
  const maxX = Math.max(...xs)
  const minY = Math.min(...ys)
  const maxY = Math.max(...ys)
  
  return {
    x: Math.round(minX),
    y: Math.round(minY),
    width: Math.round(maxX - minX),
    height: Math.round(maxY - minY)
  }
}

async function correctPerspective(imageBuffer, corners, boundingRect, logger) {
  try {
    // Simulaci√≥n de correcci√≥n de perspectiva
    // En una implementaci√≥n real usar√≠as matriz de transformaci√≥n perspectiva
    
    logger.info('üîÑ Aplicando transformaci√≥n de perspectiva...')
    
    // Calcular si es un trapecio (esquinas no forman rect√°ngulo perfecto)
    const isTrapezoidal = checkIfTrapezoidal(corners)
    
    if (isTrapezoidal) {
      logger.info('üìê Detectado trapecio, corrigiendo distorsi√≥n perspectiva')
      
      // Simular correcci√≥n aplicando transformaciones
      return await sharp(imageBuffer)
        .resize(400, 120, { fit: 'fill' }) // Forzar aspecto ratio t√≠pico de placa
        .sharpen()
        .normalize()
        .jpeg()
        .toBuffer()
    } else {
      logger.info('‚úÖ Imagen ya rectangular, aplicando mejoras b√°sicas')
      
      return await sharp(imageBuffer)
        .resize(400, 120, { fit: 'inside', withoutEnlargement: false })
        .sharpen()
        .jpeg()
        .toBuffer()
    }
    
  } catch (error) {
    logger.warning(`‚ö†Ô∏è Error en correcci√≥n perspectiva: ${error.message}`)
    return imageBuffer
  }
}

function checkIfTrapezoidal(corners) {
  // Verificar si las esquinas forman un trapecio
  // Esto es una simplificaci√≥n - en implementaci√≥n real calcular√≠as √°ngulos
  
  const [tl, tr, br, bl] = corners
  
  // Verificar si los lados superior e inferior no son paralelos
  const topSlope = (tr[1] - tl[1]) / (tr[0] - tl[0])
  const bottomSlope = (br[1] - bl[1]) / (br[0] - bl[0])
  
  const slopeDifference = Math.abs(topSlope - bottomSlope)
  
  // Si la diferencia de pendientes es significativa, es un trapecio
  return slopeDifference > 0.1
}

async function normalizePlateImage(imageBuffer, logger) {
  try {
    logger.info('üé® Aplicando normalizaci√≥n final...')
    
    // Normalizaci√≥n completa para imagen de placa √≥ptima
    const normalizedBuffer = await sharp(imageBuffer)
      .resize(400, 120, { 
        fit: 'fill',
        kernel: sharp.kernel.lanczos3 // Mejor calidad de reescalado
      })
      .greyscale() // Convertir a escala de grises para mejor contraste
      .normalize() // Normalizar histograma
      .modulate({ 
        brightness: 1.1, 
        contrast: 1.3 
      })
      .sharpen({
        sigma: 1,
        flat: 1,
        jagged: 2
      })
      .gamma(1.2) // Ajuste gamma para mejor visibilidad
      .jpeg({ quality: 95 })
      .toBuffer()
    
    logger.success('‚ú® Normalizaci√≥n completada: imagen optimizada para an√°lisis')
    
    return normalizedBuffer
    
  } catch (error) {
    logger.warning(`‚ö†Ô∏è Error en normalizaci√≥n: ${error.message}`)
    return imageBuffer
  }
}

export default defineEventHandler(async (event) => {
  const sessionId = uuidv4()
  const logger = createProcessingLogger(sessionId)
  
  const form = formidable({
    uploadDir: '/tmp',
    keepExtensions: true,
    maxFileSize: 15 * 1024 * 1024
  })

  let imagePath = null

  try {
    logger.info('üöÄ Iniciando pipeline simplificada de detecci√≥n de placas...')
    logger.info('üéØ Objetivo: Detectar, recortar y normalizar √°rea de placa vehicular')
    
    const [fields, files] = await new Promise((resolve, reject) => {
      form.parse(event.node.req, (err, fields, files) => {
        if (err) reject(err)
        else resolve([fields, files])
      })
    })

    const imageFile = Array.isArray(files.image) ? files.image[0] : files.image
    
    if (!imageFile) {
      throw new Error('No se recibi√≥ ninguna imagen')
    }

    imagePath = imageFile.filepath || imageFile.path
    logger.info(`üìÅ Imagen recibida: ${path.basename(imagePath)}`)
    
    // Guardar imagen original
    const originalBuffer = await fs.readFile(imagePath)
    await logger.saveProcessedImage(originalBuffer, PLATE_PROCESSING_STEPS.ORIGINAL, 'Imagen original recibida')

    // Paso 1: Detectar veh√≠culo (opcional, para enfocar b√∫squeda)
    const vehicleDetection = await detectVehicle(imagePath, logger)
    
    // Paso 2: Buscar contornos de placas
    const plateContours = await findPlateContours(imagePath, vehicleDetection.bbox, logger)
    
    if (!plateContours.success || plateContours.plateRegions.length === 0) {
      logger.warning('üòû No se encontraron placas en la imagen')
      
      const response = {
        success: false,
        sessionId,
        message: 'No se pudieron detectar placas en la imagen',
        hasVehicle: vehicleDetection.hasVehicle,
        vehicleType: vehicleDetection.vehicleType,
        vehicleConfidence: vehicleDetection.confidence,
        logs: logger.getLogs(),
        processedImages: logger.getProcessedImages(),
        stats: logger.getStats()
      }
      
      logger.finish()
      return response
    }
    
    // Paso 3: Extraer y corregir la mejor placa
    const plateExtraction = await extractAndCorrectPlate(
      imagePath, 
      plateContours, 
      plateContours.searchArea, 
      logger
    )
    
    // Limpiar archivo temporal
    if (imagePath) {
      await fs.unlink(imagePath).catch(() => {})
    }

    logger.timing('Pipeline completa')

    const response = {
      success: plateExtraction.success,
      sessionId,
      processingTimeMs: Date.now() - logger.startTime,
      
      // Resultados de detecci√≥n de veh√≠culo
      hasVehicle: vehicleDetection.hasVehicle,
      vehicleType: vehicleDetection.vehicleType,
      vehicleConfidence: vehicleDetection.confidence,
      
      // Resultados de detecci√≥n de placa
      hasPlate: plateExtraction.success,
      plateRegion: plateExtraction.plateRegion,
      plateDimensions: plateExtraction.dimensions,
      
      // Estad√≠sticas del procesamiento
      plateCandidatesFound: plateContours.plateRegions.length,
      
      // Datos de la sesi√≥n
      logs: logger.getLogs(),
      processedImages: logger.getProcessedImages(),
      stats: logger.getStats()
    }
    
    logger.success(`üéâ Pipeline completada: ${response.hasPlate ? 'Placa extra√≠da' : 'Sin placas detectadas'}`)
    logger.finish()
    
    return response
    
  } catch (error) {
    logger.error(`üí• Error en pipeline: ${error.message}`)
    
    if (imagePath) {
      await fs.unlink(imagePath).catch(() => {})
    }
    
    throw createError({
      statusCode: 500,
      statusMessage: `Error procesando imagen: ${error.message}`
    })
  }
})